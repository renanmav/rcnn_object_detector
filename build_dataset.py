# import the necessary packages
from rcnn_object_detection.iou import compute_iou
from rcnn_object_detection import config
from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os

# loop over the output positive and negative directories
for dirPath in (config.POSITIVE_PATH, config.NEGATIVE_PATH):
    if not os.path.exists(dirPath):
        os.makedirs(dirPath)

# grab all image paths in the input images directory
imagePaths = list(paths.list_images(config.ORIG_IMAGES))

# initialize the total number of positive and negative images we have
# saved to disk so far
totalPositive = 0
totalNegative = 0

# loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
    # show a progress report
    print(f"[INFO] processing image {i + 1}/{len(imagePaths)}")

    # extract the filename from the file path and use it derive
    # the path to the XML annotation file
    filename = imagePath.split(os.path.sep)[-1]
    filename = filename[:filename.rfind(".")]
    annotPath = os.path.sep.join([config.ORIG_ANNOTS, f"{filename}.xml"])

    # load the annotation file, build the soup, and initialize our
    # list of ground-truth bouding boxes
    contents = open(annotPath).read()
    soup = BeautifulSoup(contents, "html.parser")
    gtBoxes = []

    # extract the image dimensions
    w = int(soup.find("width").string)
    h = int(soup.find("height").string)
    
    # show a dimension report
    print(f"[INFO] image {i} has width of {w}px and height of {h}px")

    # loop over all "object" elements
    for o in soup.find_all("object"):
        # extract the label and bouding box coordinates
        label = o.find("name").string
        xMin = int(o.find("xmin").string)
        yMin = int(o.find("ymin").string)
        xMax = int(o.find("xmax").string)
        yMax = int(o.find("ymax").string)

        # truncate any bounding box coordinates that may fall
        # outside the boundaries of the image
        xMin = max(0, xMin)
        yMin = max(0, yMin)
        xMax = max(w, xMax)
        yMax = max(h, yMax)

        # update our list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax))

    # load the input image from disk
    image = cv2.imread(imagePath)

    # run selective search on the image and initialize our list of
    # proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRects = []

    # loop over the rectangles generated by selective search
    for (x, y, w, h) in rects:
        # convert our bounding boxes from (x, y, w, h) to (startX,
        # startY, endX, endY)
        proposedRects.append((x, y, x + w, y + h))

    # show a selective search report
    print(f"[INFO] selective search proposed a total of {len(proposedRects)} regions of interest for image {i}")

    # initialize counters used to count the number of positive and
    # negative ROIs salved thus far
    positiveROIs = 0
    negativeROIs = 0

    # loop over the maximum number of region proposals
    for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
        # unpack the proposed rectangle bounding box
        (propStartX, propStartY, propEndX, propEndY) = proposedRect

        # loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
            # compute the intersection over union between the two
            # boxes and upack the ground-truth bounding box
            iou = compute_iou(gtBox, proposedRect)
            (gtStartX, gtStartY, gtEndX, gtEndY) = gtBox

            # initialize the ROI and output path
            roi = None
            outputPath = None

            # check to see if the IOU is greater than 90% *and* that
            # we have not hit our positive count limit
            if iou > 0.9 and positiveROIs <= config.MAX_POSITIVE:
                # extract the ROI and then derive the output path to
                # the positive instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = f"{totalPositive}.png"
                outputPath = os.path.sep.join([config.POSITIVE_PATH, filename])

                # increment the positive counters
                positiveROIs += 1
                totalPositive += 1

            # determine if the proposed bounding box falls "within"
            # the ground-truth bouding box
            fullOverlap = propStartX >= gtStartX
            fullOverlap = fullOverlap and propStartY >= gtStartY
            fullOverlap = fullOverlap and propEndX <= gtEndX
            fullOverlap = fullOverlap and propEndY <= gtEndY

            # check to see if there is not full overlap *and* the IOU
            # is less than 5% *and* we have not hit our negative
            # count limit
            if not fullOverlap and iou < 0.05 and \
                negativeROIs <= config.MAX_NEGATIVE:
                # extract the ROI and then derive the output path to
                # the negative instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = f"{totalNegative}.png"
                outputPath = os.path.sep.join([config.NEGATIVE_PATH, filename])

                # increment the negative counters
                negativeROIs += 1
                totalNegative += 1

            # check to see if both the ROI and outputPath are valid
            if roi is not None and outputPath is not None:
                # resize the ROI to the input dimensions of the CNN
                # that we'll be fine-tuning, then write the ROI to
                # disk
                roi = cv2.resize(roi, config.INPUT_DIMS, interpolation=cv2.INTER_CUBIC)
                cv2.imwrite(outputPath, roi)